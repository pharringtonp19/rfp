{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xm90aUV7ERtu"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, Sequence\n",
        "import jax \n",
        "import jax.numpy as jnp\n",
        "from jax import Array\n",
        "import flax.linen as nn \n",
        "from functools import partial \n",
        "from tqdm import tqdm \n",
        "from einops import rearrange, repeat\n",
        "import optax \n",
        "from diffrax import diffeqsolve, ODETerm, Dopri5\n",
        "from tqdm import tqdm \n",
        "from rfp import MLP, Model, ModelParams\n",
        "from rfp.losses import Supervised_Loss, mse, Cluster_Loss\n",
        "from rfp.train import Trainer"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Path**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "figure_folders = './../../../rfp_paper/figures/'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Set Up Plotting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import rcParams\n",
        "rcParams['image.interpolation'] = 'nearest'\n",
        "rcParams['image.cmap'] = 'viridis'\n",
        "rcParams['axes.grid'] = False\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "plt.style.use('seaborn-v0_8-dark-palette')\n",
        "\n",
        "from matplotlib import font_manager \n",
        "locations = './../../styles/Newsreader'\n",
        "font_files = font_manager.findSystemFonts(fontpaths=locations)\n",
        "print(locations)\n",
        "print(font_files[0])\n",
        "for f in font_files: \n",
        "    font_manager.fontManager.addfont(f)\n",
        "plt.rcParams[\"font.family\"] = \"Newsreader\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Data Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwwRjD0rEpyi",
        "outputId": "27ffa887-d7c4-4b07-b63a-3554eb052b7f"
      },
      "outputs": [],
      "source": [
        "n = 50             \n",
        "d = 1             \n",
        "c = 3\n",
        "k = 2           \n",
        "init_key = jax.random.PRNGKey(0)\n",
        "nodes = 64\n",
        "inner_lr = 1e-3\n",
        "lr = 1e-3\n",
        "epochs = 5000 \n",
        "inner_epochs = 5\n",
        "simulations = 100\n",
        "reg_value = .9"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Value to Key**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def value_to_key(value: float) -> jax.random.PRNGKey:\n",
        "    # Ensure value is in the range [0, 1]\n",
        "    \n",
        "    # Scale value to the range of PRNG key integers\n",
        "    max_int = jnp.iinfo(jnp.int32).max\n",
        "    scaled_value = jnp.array(value * max_int, dtype=jnp.int32)\n",
        "    \n",
        "    # Create a new key using the scaled value\n",
        "    key = jax.random.PRNGKey(scaled_value)\n",
        "    \n",
        "    return key"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Generate Conditional Expectation Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "  features: Sequence[int]\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs):\n",
        "    x = inputs\n",
        "    for i, feat in enumerate(self.features):\n",
        "      x = nn.Dense(feat, name=f'layers_{i}')(x)\n",
        "      if i != len(self.features) - 1:\n",
        "        x = nn.hard_swish(x)\n",
        "    return x\n",
        "base_model = SimpleMLP( [nodes, nodes, 1])\n",
        "\n",
        "def gen_outcome(params_key, features):\n",
        "    a, b, c = jax.random.normal(params_key, shape=(3,))\n",
        "    f = lambda x: a*x**2 + b*x + c\n",
        "    return jax.vmap(f)(features)\n",
        "\n",
        "def gen_outcome(params_key, features):\n",
        "    k1, k2 = jax.random.split(params_key)\n",
        "    mus = jax.random.normal(k1, shape=(10,))\n",
        "    alphas = jax.random.normal(k2, shape=(10,))\n",
        "    f = lambda x: jnp.dot(partial(jax.scipy.stats.norm.pdf, x)(mus), alphas)\n",
        "    ys = jax.vmap(f)(features)\n",
        "    return ys.reshape(-1,1)\n",
        "\n",
        "def gen_outcome(params_key, features):\n",
        "    a = jax.random.normal(params_key, shape=(1,))\n",
        "    f = lambda x: a*x\n",
        "    return jax.vmap(f)(features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gen_outcome(params_key, features):\n",
        "    \n",
        "    def main_effect(x, p):\n",
        "      return jnp.log(x**2 + 1.0 + jnp.sin(x*3.0)) + 1.5 + jnp.abs(x)*p\n",
        "    p = jax.random.uniform(params_key, minval=0.5, maxval=5., shape=(1,))\n",
        "    return jax.vmap(partial(main_effect, p=p))(features)\n",
        "\n",
        "\n",
        "key = jax.random.PRNGKey(0)\n",
        "for _ in range(100):\n",
        "    key, k1, k2 = jax.random.split(key, 3)\n",
        "    xs = jnp.linspace(-3., 3., 1000)\n",
        "    ys = gen_outcome(k2, xs)\n",
        "    idx = jnp.argsort(xs.reshape(-1,))\n",
        "    plt.plot(xs[idx], ys[idx])\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Sample Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample(key, n, d):\n",
        "    k1, k2, k3 = jax.random.split(key, 3)\n",
        "    cluster_feature = jax.random.uniform(k2)\n",
        "    params_key = value_to_key(cluster_feature)\n",
        "    means = jax.random.normal(k1, shape=(d,)) #jnp.zeros(shape=(d,))#\n",
        "    xs = jax.random.multivariate_normal(k2, mean=means, cov=jnp.eye(d), shape=(n,))\n",
        "    features = xs \n",
        "    outcomes = gen_outcome(params_key, features)\n",
        "    return features, outcomes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlp = MLP([nodes, nodes], jax.nn.relu)\n",
        "final_activation_fn = lambda x: x; print(f\"Final Activation Function: {final_activation_fn}\")\n",
        "model = Model(mlp, final_activation_fn)\n",
        "supervised_loss = Supervised_Loss(mse, model.fwd_pass) #*** I am not sure this is correct***\n",
        "standard_yuri = Trainer(supervised_loss, optax.sgd(learning_rate=lr, momentum=0.9), epochs)\n",
        "\n",
        "\n",
        "inner_yuri = Trainer(supervised_loss, optax.sgd(learning_rate=inner_lr), inner_epochs)\n",
        "cluster_loss_train = Cluster_Loss(inner_yuri, reg_value)\n",
        "cluster_loss_val = Cluster_Loss(inner_yuri, 0.0)\n",
        "cluster_yuri = Trainer(cluster_loss_train,   optax.sgd(learning_rate=lr, momentum=0.9), epochs, val_loss_fn=cluster_loss_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_data_params(key, n, c, d):\n",
        "    k1, k2, k3 = jax.random.split(key, 3)\n",
        "    batch_inputs, batch_outcomes  = jax.vmap(partial(sample, n=n, d=d))(jax.random.split(k1, c))\n",
        "    inputs = rearrange(batch_inputs, 'a b c -> (a b) c')\n",
        "    outcomes = rearrange(batch_outcomes, 'a b c -> (a b) c')\n",
        "    inputs_standardized = jax.nn.standardize(inputs, axis=0)\n",
        "    batch_inputs_standarized = rearrange(inputs_standardized, '(a b) c -> a b c', a=c)\n",
        "\n",
        "    train_group = jax.random.choice(k2, jnp.arange(c), replace=False, shape=(k,))\n",
        "    training_group = jnp.isin(jnp.arange(c), train_group)\n",
        "    training_mask = jnp.repeat(training_group, n)\n",
        "    validation_mask = ~training_mask\n",
        "    batch_training_mask = rearrange(training_mask, '(a b) -> a b', a=c)\n",
        "    batch_validation_mask = rearrange(validation_mask, '(a b) -> a b', a=c)\n",
        "\n",
        "    params = ModelParams.init_fn(k3, mlp, d)\n",
        "\n",
        "    return {'inputs_standarized': inputs_standardized,\n",
        "            'batch_inputs_standarized': batch_inputs_standarized,\n",
        "            'outcomes': outcomes,\n",
        "            'batch_outcomes': batch_outcomes, \n",
        "            'training_group': training_group,\n",
        "            'training_mask': training_mask, \n",
        "            'batch_training_mask': batch_training_mask,\n",
        "            'validation_mask': validation_mask, \n",
        "            'batch_validation_mask': batch_validation_mask,\n",
        "            'params': params, \n",
        "            }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def cluster_simulate(key, n, c, d):\n",
        "    setup = get_data_params(key, n, c, d)\n",
        "    params, opt_params, training_loss, validation_loss = cluster_yuri.train_with_val(setup['params'],\n",
        "                                                                                setup['batch_inputs_standarized'],\n",
        "                                                                                setup['batch_outcomes'],\n",
        "                                                                                mask=jnp.ones_like(setup['batch_outcomes']), \n",
        "                                                                                train_idx=setup['batch_training_mask'], \n",
        "                                                                                val_idx=setup['batch_validation_mask'])\n",
        "    return  training_loss, validation_loss, (setup['batch_inputs_standarized'], setup['batch_outcomes'], jax.vmap(model.fwd_pass, in_axes=(None, 0))(params, setup['batch_inputs_standarized']), setup['training_group'])\n",
        "\n",
        "def standard_simulate(key, n, c, d):\n",
        "    setup = get_data_params(key, n, c, d)\n",
        "    params, opt_params, training_loss, validation_loss = standard_yuri.train_with_val(setup['params'], \n",
        "                                                                                      setup['inputs_standarized'],  \n",
        "                                                                                      setup['outcomes'], \n",
        "                                                                                      mask=jnp.ones_like(setup['outcomes']), \n",
        "                                                                                      train_idx=setup['training_mask'], \n",
        "                                                                                      val_idx=setup['validation_mask'])\n",
        "    return  training_loss, validation_loss, (setup['batch_inputs_standarized'], setup['batch_outcomes'], jax.vmap(model.fwd_pass, in_axes=(None, 0))(params, setup['batch_inputs_standarized']), setup['training_group'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in xss:\n",
        "    plt.plot(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "if d == 1:\n",
        "    kk = 0\n",
        "    ts, vs, (xss, yss, yhatss, tg) = standard_simulate(jax.random.key(kk), n, c, d)\n",
        "    tsc, vsc, (xss, yss, yhatsc, tg) = cluster_simulate(jax.random.key(kk), n, c, d)\n",
        "    print(f\"Minimum Validation Loss: Standard --> {jnp.min(vs):.3f} | Cluster -->  {jnp.min(vsc):.3f}\")\n",
        "    print(f\"Final Validation Loss: Standard --> {vs[-1]:.3f} | Cluster -->  {vsc[-1]:.3f}\")\n",
        "\n",
        "    ###\n",
        "    for z, (i, j) in enumerate(zip(xss, yss)):\n",
        "        if tg[z]:\n",
        "            idx = jnp.argsort(i[:,0])\n",
        "            plt.scatter(i[:,0][idx], j[idx], color='black')\n",
        "    xs = rearrange(xss, 'a b c -> (a b) c').reshape(-1,1)\n",
        "    print(xs.shape)\n",
        "    idx = jnp.argsort(xs.reshape(-1,))\n",
        "    yhats = rearrange(yhatss, 'a b c -> (a b) c')\n",
        "    yhatc = rearrange(yhatsc, 'a b c -> (a b) c')\n",
        "    plt.plot(xs[idx], yhats[idx], linestyle='--', label='Standard', linewidth=2.5)\n",
        "    plt.plot(xs[idx], yhatc[idx], linestyle='--', label='Cluster', linewidth=2.5)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    ###\n",
        "    for z, (i, j) in enumerate(zip(xss, yss)):\n",
        "        if not tg[z]:\n",
        "            idx = jnp.argsort(i[:,0])\n",
        "            plt.scatter(i[:,0][idx], j[idx], color='black')\n",
        "    xs = rearrange(xss, 'a b c -> (a b) c')[:,0].reshape(-1,1)\n",
        "    print(xs.shape)\n",
        "    idx = jnp.argsort(xs.reshape(-1,))\n",
        "    yhats = rearrange(yhatss, 'a b c -> (a b) c')\n",
        "    yhatc = rearrange(yhatsc, 'a b c -> (a b) c')\n",
        "    plt.plot(xs[idx], yhats[idx], linestyle='--', label='Standard', linewidth=2.5)\n",
        "    plt.plot(xs[idx], yhatc[idx], linestyle='--', label='Cluster', linewidth=2.5)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(vs, label='Standard')\n",
        "    plt.plot(vsc, label='Cluster')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    plt.plot(ts, label='Standard')\n",
        "    plt.plot(tsc, label='Cluster')\n",
        "    plt.ylim(0,3)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = {'standard': {'training_loss': [], 'validation_loss': []},\n",
        "           'cluster': {'training_loss': [], 'validation_loss': []}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "key = init_key\n",
        "for _ in tqdm(range(simulations)):\n",
        "    t, v, _ = standard_simulate(key, n, c, d)\n",
        "    results['standard']['training_loss'].append(t)\n",
        "    results['standard']['validation_loss'].append(v)\n",
        "    key, _ = jax.random.split(key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "key = init_key\n",
        "for _ in tqdm(range(simulations)):\n",
        "    t, v, _ = cluster_simulate(key, n, c, d)\n",
        "    results['cluster']['training_loss'].append(t)\n",
        "    results['cluster']['validation_loss'].append(v)\n",
        "    key, _ = jax.random.split(key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "standard_last = jnp.array([i[-1] for i in results['standard']['validation_loss']])\n",
        "rfp_last = jnp.array([i[-1] for i in results['cluster']['validation_loss']])\n",
        "print(jnp.mean(standard_last), jnp.mean(rfp_last))            \n",
        "\n",
        "# Create bar graph\n",
        "fig = plt.figure(dpi=300, tight_layout=True, figsize=(4, 4.5))\n",
        "ax = plt.axes(facecolor=(.95, .96, .97))\n",
        "ax.xaxis.set_tick_params(length=0, labeltop=False, labelbottom=True)\n",
        "\n",
        "for key in 'left', 'right', 'top':\n",
        "    ax.spines[key].set_visible(False)\n",
        "\n",
        "subtitle = 'Validation Loss'\n",
        "ax.text(0., 1.02, s=subtitle, transform=ax.transAxes, size=14)\n",
        "ax.yaxis.set_tick_params(length=0)\n",
        "ax.yaxis.grid(True, color='white', linewidth=2)\n",
        "ax.set_axisbelow(True)\n",
        "plt.plot(standard_last/standard_last, label='Standard')\n",
        "plt.plot(rfp_last/standard_last, label='RFP')\n",
        "plt.xlabel('Random Seeds', size=14)\n",
        "plt.legend()\n",
        "plt.ylim(0, 2)\n",
        "#fig.savefig(figure_folders + f'naive_exp1_{n}_{c}_{d}_{epochs}_{inner_epochs}.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "standard = jnp.array([jnp.min(jnp.array(i)) for i in results['standard']['validation_loss']])\n",
        "rfp = jnp.array([jnp.min(jnp.array(i)) for i in results['cluster']['validation_loss']])\n",
        "\n",
        "print(jnp.mean(standard), jnp.mean(rfp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create bar graph\n",
        "fig = plt.figure(dpi=300, tight_layout=True, figsize=(4, 4.5))\n",
        "ax = plt.axes(facecolor=(.95, .96, .97))\n",
        "ax.xaxis.set_tick_params(length=0, labeltop=False, labelbottom=True)\n",
        "\n",
        "for key in 'left', 'right', 'top':\n",
        "    ax.spines[key].set_visible(False)\n",
        "\n",
        "subtitle = 'Validation Loss'\n",
        "ax.text(0., 1.02, s=subtitle, transform=ax.transAxes, size=14)\n",
        "ax.yaxis.set_tick_params(length=0)\n",
        "ax.yaxis.grid(True, color='white', linewidth=2)\n",
        "ax.set_axisbelow(True)\n",
        "plt.plot(standard/standard, label='Standard')\n",
        "plt.plot(jnp.minimum(rfp/standard, 2.0), label='RFP')\n",
        "plt.xlabel('Random Seeds', size=14)\n",
        "plt.legend()\n",
        "plt.ylim(0, 2)\n",
        "#fig.savefig(figure_folders + f'naive_exp1_{n}_{c}_{d}_{epochs}_{inner_epochs}.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "means = [jnp.mean(standard_last)/jnp.mean(standard_last), jnp.mean(rfp_last)/jnp.mean(standard_last), jnp.mean(standard)/jnp.mean(standard), jnp.mean(rfp)/jnp.mean(standard)]\n",
        "\n",
        "# Positions of the bars\n",
        "positions = [-0.2, 0.2, 1.0, 1.4]\n",
        "\n",
        "# Labels for the x-axis\n",
        "labels = ['Training Convergence', 'Training Convergence', 'Early Stopping', 'Early Stopping']\n",
        "\n",
        "# Colors for the bars\n",
        "colors = ['#36454F', 'purple', '#36454F', 'purple']\n",
        "\n",
        "# Plotting\n",
        "fig = plt.figure(dpi=300, tight_layout=True, figsize=(4.5, 4.5))\n",
        "ax = plt.axes(facecolor=(.95, .96, .97))\n",
        "\n",
        "# Plot customizations\n",
        "for key in 'left', 'right', 'top':\n",
        "    ax.spines[key].set_visible(False)\n",
        "ax.text(0., 1.02, s='Validation Loss', transform=ax.transAxes, size=14)\n",
        "ax.yaxis.set_tick_params(length=0)\n",
        "ax.yaxis.grid(True, color='white', linewidth=2)\n",
        "ax.set_axisbelow(True)\n",
        "\n",
        "bars = ax.bar(positions, means, width=0.4, color=colors)\n",
        "\n",
        "# Adding labels and title\n",
        "ax.set_xticks([0, 1.2])\n",
        "ax.set_xticklabels(['Training Convergence', 'Early Stopping'], size=14)\n",
        "\n",
        "# Adding custom legend\n",
        "import matplotlib.patches as mpatches\n",
        "standard_patch = mpatches.Patch(color='#36454F', label='Standard')\n",
        "rfp_patch = mpatches.Patch(color='purple', label='RFP')\n",
        "ax.legend(handles=[standard_patch, rfp_patch], loc='upper right')\n",
        "plt.ylim(0, 1.2)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPh4V8qejmlYUARsk94Vlb8",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "local_weighted_linear_regression_no_avg_effect_LM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
