{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax \n",
    "import jax.numpy as jnp \n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, Tuple, Dict\n",
    "import optax \n",
    "import matplotlib.pyplot as plt \n",
    "from datasets import load_dataset\n",
    "from transformers import FlaxAutoModelForMaskedLM, AutoTokenizer\n",
    "from transformers import FlaxAutoModelForSequenceClassification, AutoConfig\n",
    "from rfp.losses import Supervised_Loss, softmax_cross_entropy, Cluster_Loss\n",
    "from rfp.train import Trainer  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer.model_max_length = 512\n",
    "print(tokenizer.model_max_length)\n",
    "config = AutoConfig.from_pretrained(model_checkpoint, num_labels=2)\n",
    "model = FlaxAutoModelForSequenceClassification.from_pretrained(model_checkpoint, config=config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tokenize Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_function(batch):\n",
    "    # Assuming 'text' is the field you want to tokenize; adjust accordingly.\n",
    "    text_data = batch['text']  # Adjust this if another text field should be tokenized.\n",
    "    \n",
    "    # Tokenize the text data\n",
    "    tokens = tokenizer(text_data, return_tensors=\"jax\", padding='max_length', truncation=True)\n",
    "    \n",
    "    # Convert tokenized data to JAX arrays and return\n",
    "    tokens = {key: jnp.array(value) for key, value in tokens.items() if key in ['input_ids', 'attention_mask', 'label']}\n",
    "    \n",
    "    return tokens\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Load and Process Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = load_dataset(\"ppower1/instrument\")['train']\n",
    "original_dataset = original_dataset.map(tokenizer_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(original_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Define Forward Pass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfp(params, tokens):\n",
    "    return model(tokens['input_ids'], tokens['attention_mask'], params=params).logits, 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_loss = Supervised_Loss(softmax_cross_entropy,  rfp)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_loss(model.params, original_dataset, jnp.array(original_dataset['label']).astype(jnp.float32), jnp.ones(shape=(len(original_dataset), 1)).astype(jnp.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rfp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
